{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', None)   # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)  # Adjust the width to display full table\n",
    "pd.set_option('display.max_colwidth', None)  # Adjust column width to avoid truncation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"finalv1_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 384846 entries, 0 to 384845\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Non-Null Count   Dtype \n",
      "---  ------                     --------------   ----- \n",
      " 0   From                       384846 non-null  object\n",
      " 1   To                         384846 non-null  object\n",
      " 2   Subject                    384846 non-null  object\n",
      " 3   X-cc                       384846 non-null  object\n",
      " 4   X-bcc                      384846 non-null  object\n",
      " 5   Content                    384846 non-null  object\n",
      " 6   Job_Title                  384846 non-null  object\n",
      " 7   Total_Sentence_Word_Count  384846 non-null  int64 \n",
      " 8   From_Names                 384846 non-null  object\n",
      " 9   To_Names                   380598 non-null  object\n",
      " 10  Cleaned_Content            384846 non-null  object\n",
      " 11  BoW                        384846 non-null  object\n",
      " 12  DateTime                   384846 non-null  object\n",
      "dtypes: int64(1), object(12)\n",
      "memory usage: 38.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spaCy model...\n",
      "Model loaded in 2.94 seconds\n",
      "Applying NER to DataFrame...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04589eb55bac43e9ba2f788a59238e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/384846 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total application time: 9747.19 seconds\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import spacy\n",
    "import time\n",
    "\n",
    "# Enable tqdm for pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Time the loading of the spaCy model\n",
    "print(\"Loading spaCy model...\")\n",
    "start_time = time.time()\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=[\"tagger\", \"parser\", \"lemmatizer\"])\n",
    "model_load_time = time.time() - start_time\n",
    "print(f\"Model loaded in {model_load_time:.2f} seconds\")\n",
    "\n",
    "# Function to extract named entities for a single text\n",
    "def extract_named_entities_spacy(text):\n",
    "    \"\"\"\n",
    "    Extracts named entities from a single text using spaCy's pre-trained model.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to process.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of (entity, label) tuples for the text.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents if ent.text.strip()]\n",
    "    return entities\n",
    "\n",
    "\n",
    "# Apply NER extraction with timing and progress_apply\n",
    "start_time = time.time()\n",
    "print(\"Applying NER to DataFrame...\")\n",
    "df['NER_Entities'] = df['Cleaned_Content'].progress_apply(extract_named_entities_spacy)\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total application time: {total_time:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('FULL_NER.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERSON:      People, including fictional.\n",
    "NORP:        Nationalities or religious or political groups.\n",
    "FAC:         Buildings, airports, highways, bridges, etc.\n",
    "ORG:         Companies, agencies, institutions, etc.\n",
    "GPE:         Countries, cities, states.\n",
    "LOC:         Non-GPE locations, mountain ranges, bodies of water.\n",
    "PRODUCT:     Objects, vehicles, foods, etc. (Not services.)\n",
    "EVENT:       Named hurricanes, battles, wars, sports events, etc.\n",
    "WORK_OF_ART: Titles of books, songs, etc.\n",
    "LAW:         Named documents made into laws.\n",
    "LANGUAGE:    Any named language.\n",
    "DATE:        Absolute or relative dates or periods.\n",
    "TIME:        Times smaller than a day.\n",
    "PERCENT:     Percentage, including ”%“.\n",
    "MONEY:       Monetary values, including unit.\n",
    "QUANTITY:    Measurements, as of weight or distance.\n",
    "ORDINAL:     “first”, “second”, etc.\n",
    "CARDINAL:    Numerals that do not fall under another type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('FULL_NER.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               [('austin', 'PERSON')]\n",
       "1      [('randy send', 'PERSON'), ('patti', 'PERSON')]\n",
       "2    [('phillip allen pallenenroncom', 'PERSON'), (...\n",
       "3    [('1', 'CARDINAL'), ('ke9davis', 'NORP'), ('is...\n",
       "4    [('phillip k', 'PERSON'), ('10162000', 'CARDIN...\n",
       "Name: NER_Entities, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.NER_Entities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Named_Entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'PERSON': ['austin']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'PERSON': ['randy send', 'patti']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'PERSON': ['mike grigsby', 'phillip allen', 'phillip allen pallenenroncom', 'keith holst kholstenroncom', 'john lavorato', 'monique sanchez frank']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'CARDINAL': ['255255255248', '6421690110', '6421690105', '105891', '1'], 'NORP': ['ke9davis'], 'ORG': ['isp 2'], 'DATE': ['15116418 3 0413']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'PERSON': ['buckner buck', 'phillip k'], 'CARDINAL': ['75', '240', '10162000', '180', 'kwh', '60100', '180 240', '302'], 'MONEY': ['10122000 011221'], 'ORG': ['pan american frwy', 'pallenenroncom pallenenroncom', 'honeywell power systems inc 8725', 'buckner pe mba', 'honeywell', 'ldc san diego gas electric'], 'GPE': ['san diego'], 'TIME': ['68 hours'], 'DATE': ['87113 5057986424', '5052204129 8885013145', 'september']}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                            Named_Entities\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                   {'PERSON': ['austin']}\n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                      {'PERSON': ['randy send', 'patti']}\n",
       "2                                                                                                                                                                                                                                                                                    {'PERSON': ['mike grigsby', 'phillip allen', 'phillip allen pallenenroncom', 'keith holst kholstenroncom', 'john lavorato', 'monique sanchez frank']}\n",
       "3                                                                                                                                                                                                                                                                                           {'CARDINAL': ['255255255248', '6421690110', '6421690105', '105891', '1'], 'NORP': ['ke9davis'], 'ORG': ['isp 2'], 'DATE': ['15116418 3 0413']}\n",
       "4  {'PERSON': ['buckner buck', 'phillip k'], 'CARDINAL': ['75', '240', '10162000', '180', 'kwh', '60100', '180 240', '302'], 'MONEY': ['10122000 011221'], 'ORG': ['pan american frwy', 'pallenenroncom pallenenroncom', 'honeywell power systems inc 8725', 'buckner pe mba', 'honeywell', 'ldc san diego gas electric'], 'GPE': ['san diego'], 'TIME': ['68 hours'], 'DATE': ['87113 5057986424', '5052204129 8885013145', 'september']}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Function to process NER_Entities into a dictionary of entity types and values\n",
    "def process_ner_entities(row):\n",
    "    # If row is a string, parse it into a Python object\n",
    "    if isinstance(row, str):\n",
    "        try:\n",
    "            row = ast.literal_eval(row)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return {}  # Return empty dict for unparsable rows\n",
    "    \n",
    "    # Ensure row is iterable\n",
    "    if not isinstance(row, (list, tuple)):\n",
    "        return {}  # Return empty dict for invalid rows\n",
    "    \n",
    "    # Process tuples into a dictionary\n",
    "    result = {}\n",
    "    for item in row:\n",
    "        if isinstance(item, tuple) and len(item) == 2:  # Only process tuples with exactly 2 values\n",
    "            entity, entity_type = item\n",
    "            if entity_type not in result:\n",
    "                result[entity_type] = []\n",
    "            result[entity_type].append(entity)\n",
    "        # Skip tuples with 1 value or other lengths\n",
    "    \n",
    "    # Remove duplicates within each type\n",
    "    for entity_type in result:\n",
    "        result[entity_type] = list(set(result[entity_type]))\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Add a new column with the processed entity dictionaries\n",
    "df['Named_Entities'] = df['NER_Entities'].apply(process_ner_entities)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df[['Named_Entities']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 entity types overall:\n",
      "PERSON: 2486963 occurrences\n",
      "CARDINAL: 1189511 occurrences\n",
      "DATE: 1146268 occurrences\n",
      "ORG: 1012613 occurrences\n",
      "GPE: 307905 occurrences\n"
     ]
    }
   ],
   "source": [
    "# Count entity types across all rows\n",
    "entity_type_counts = Counter()\n",
    "for named_entities in test['Named_Entities']:\n",
    "    for entity_type, entities in named_entities.items():\n",
    "        entity_type_counts[entity_type] += len(entities)  # Count the number of entities for each type\n",
    "\n",
    "# Get the top 5 most frequent entity types\n",
    "top_5_entity_types = entity_type_counts.most_common(5)\n",
    "\n",
    "# Display the results\n",
    "print(\"Top 5 entity types overall:\")\n",
    "for entity_type, count in top_5_entity_types:\n",
    "    print(f\"{entity_type}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 entity types overall:\n",
      "PERSON: 2486963 occurrences\n",
      "CARDINAL: 1189511 occurrences\n",
      "DATE: 1146268 occurrences\n",
      "ORG: 1012613 occurrences\n",
      "GPE: 307905 occurrences\n",
      "\n",
      "Top 5 most frequent PERSON entity values:\n",
      "jeff: 13623 occurrences\n",
      "chris: 13320 occurrences\n",
      "vince: 8044 occurrences\n",
      "john: 7360 occurrences\n",
      "mike: 7350 occurrences\n",
      "\n",
      "Top 5 most frequent CARDINAL entity values:\n",
      "one: 43648 occurrences\n",
      "2: 38047 occurrences\n",
      "1: 33034 occurrences\n",
      "two: 30256 occurrences\n",
      "3: 23295 occurrences\n",
      "\n",
      "Top 5 most frequent DATE entity values:\n",
      "today: 40303 occurrences\n",
      "monday: 22361 occurrences\n",
      "thursday: 21594 occurrences\n",
      "tomorrow: 19428 occurrences\n",
      "friday: 17904 occurrences\n",
      "\n",
      "Top 5 most frequent ORG entity values:\n",
      "ferc: 11773 occurrences\n",
      "ena: 9775 occurrences\n",
      "eol: 6780 occurrences\n",
      "pge: 5518 occurrences\n",
      "isda: 4477 occurrences\n",
      "\n",
      "Top 5 most frequent GPE entity values:\n",
      "houston: 32951 occurrences\n",
      "california: 18752 occurrences\n",
      "texas: 18535 occurrences\n",
      "london: 8333 occurrences\n",
      "us: 7570 occurrences\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Step 1: Count entity types across all rows (overall top 5 entity types)\n",
    "entity_type_counts = Counter()\n",
    "for named_entities in test['Named_Entities']:\n",
    "    for entity_type, entities in named_entities.items():\n",
    "        entity_type_counts[entity_type] += len(entities)  # Count total unique entities per type\n",
    "\n",
    "# Get the top 5 most frequent entity types overall\n",
    "top_5_entity_types = entity_type_counts.most_common(5)\n",
    "print(\"Top 5 entity types overall:\")\n",
    "for entity_type, count in top_5_entity_types:\n",
    "    print(f\"{entity_type}: {count} occurrences\")\n",
    "\n",
    "# Step 2: Find top rows with the most entities for each of the top 5 entity types\n",
    "# Add a column to store the count of each entity type per row for sorting\n",
    "for entity_type, _ in top_5_entity_types:\n",
    "    test[f'{entity_type}_count'] = test['Named_Entities'].apply(\n",
    "        lambda x: len(x.get(entity_type, []))\n",
    "    )\n",
    "    \n",
    "# Display top 5 most frequent values for each top entity type\n",
    "for entity_type, _ in top_5_entity_types:\n",
    "    print(f\"\\nTop 5 most frequent {entity_type} entity values:\")\n",
    "    top_values = entity_value_counts[entity_type].most_common(5)\n",
    "    for value, count in top_values:\n",
    "        print(f\"{value}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 4: Combine the top 5 DataFrames into one\n",
    "# combined_df = pd.concat([top_dfs[entity_type] for entity_type in top_dfs], ignore_index=True)\n",
    "\n",
    "# # Step 5: Add all count columns to the combined DataFrame\n",
    "# for entity_type, _ in top_5_entity_types:\n",
    "#     combined_df[f'{entity_type}_count'] = combined_df['index'].apply(\n",
    "#         lambda idx: test.loc[idx, f'{entity_type}_count'] if idx in test.index else 0\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df.to_csv('TOP_NER.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERSON:      People, including fictional.\n",
    "NORP:        Nationalities or religious or political groups.\n",
    "FAC:         Buildings, airports, highways, bridges, etc.\n",
    "ORG:         Companies, agencies, institutions, etc.\n",
    "GPE:         Countries, cities, states.\n",
    "LOC:         Non-GPE locations, mountain ranges, bodies of water.\n",
    "PRODUCT:     Objects, vehicles, foods, etc. (Not services.)\n",
    "EVENT:       Named hurricanes, battles, wars, sports events, etc.\n",
    "WORK_OF_ART: Titles of books, songs, etc.\n",
    "LAW:         Named documents made into laws.\n",
    "LANGUAGE:    Any named language.\n",
    "DATE:        Absolute or relative dates or periods.\n",
    "TIME:        Times smaller than a day.\n",
    "PERCENT:     Percentage, including ”%“.\n",
    "MONEY:       Monetary values, including unit.\n",
    "QUANTITY:    Measurements, as of weight or distance.\n",
    "ORDINAL:     “first”, “second”, etc.\n",
    "CARDINAL:    Numerals that do not fall under another type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
