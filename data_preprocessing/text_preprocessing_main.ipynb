{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af24f35e-25e0-42d7-a264-e12dfc300cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from tqdm.notebook import tqdm\n",
    "df = pd.read_csv('main_data.csv')\n",
    "pd.set_option('display.max_rows', None)   # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)  # Adjust the width to display full table\n",
    "pd.set_option('display.max_colwidth', None)  # Adjust column width to avoid truncation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04b376ba-bd94-4c75-81a3-9101966a8aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 480062 entries, 0 to 480061\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count   Dtype \n",
      "---  ------                     --------------   ----- \n",
      " 0   Message-ID                 480062 non-null  object\n",
      " 1   Date                       480062 non-null  object\n",
      " 2   Time                       480062 non-null  int64 \n",
      " 3   From                       480062 non-null  object\n",
      " 4   To                         480062 non-null  object\n",
      " 5   Subject                    480062 non-null  object\n",
      " 6   X-cc                       480062 non-null  object\n",
      " 7   X-bcc                      480062 non-null  object\n",
      " 8   Content                    480062 non-null  object\n",
      " 9   Job_Title                  480062 non-null  object\n",
      " 10  Total_Sentence_Word_Count  480062 non-null  int64 \n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 40.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2c3401c-cbbc-4956-ab6d-6b28461e0569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe5ebf09-e92e-4f4e-ac7f-e8d80878325d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df266c538924919a936577a7b545469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/480062 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b62c6b6b7eb47269c9bcebcef6d3808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/480062 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0088d685d74943f6b92bbd9b756a41dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/480062 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491c70ef624e47d7bc7c4fb2224ad43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/480062 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_names(email):\n",
    "    if pd.isna(email):\n",
    "        return None\n",
    "    # Extract the username part of the email\n",
    "    matches = re.findall(r'([\\w\\.-]+)@[\\w\\.-]+', email)\n",
    "    if matches:\n",
    "        # Replace non-alphabetic characters (except spaces) with a space\n",
    "        cleaned_names = [re.sub(r'[^a-zA-Z]', ' ', name).strip() for name in matches]\n",
    "        return ', '.join(cleaned_names)\n",
    "    return None\n",
    "\n",
    "tqdm.pandas()  # Enable tqdm for pandas apply\n",
    "# Apply the function to both columns, handling multiple emails in a row\n",
    "df['From_Names'] = df['From'].str.split(',').progress_apply(lambda x: [extract_names(email.strip()) for email in x])\n",
    "df['To_Names'] = df['To'].str.split(',').progress_apply(lambda x: [extract_names(email.strip()) for email in x])\n",
    "\n",
    "# Convert lists to comma-separated strings for readability\n",
    "df['From_Names'] = df['From_Names'].progress_apply(lambda x: ', '.join(filter(None, x)))\n",
    "df['To_Names'] = df['To_Names'].progress_apply(lambda x: ', '.join(filter(None, x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2740c3b-3f01-4ce7-b326-45af1491e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c1965db-6692-44b0-969c-693a956f8d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93023f7f19454aaca852377ab8a4d4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/480062 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # Download required NLTK data (run once if not already downloaded)\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Preprocessing function with your custom stopwords included\n",
    "def preprocess_text(text):\n",
    "    # Normalize whitespace, lowercase, and strip\n",
    "    text = re.sub(r'\\s+', ' ', text.lower().strip())\n",
    "    \n",
    "    # Remove punctuation (keeps letters, numbers, and spaces only)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Get default English stopwords from NLTK\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Define your custom stopwords\n",
    "    custom_stopwords = {\n",
    "        \"enron\", \"email\", \"subject\", \"company\", \"corporate\", \"mary\", \"hain\", \"hou\", \"ect\", \n",
    "        \"mark\", \"hainhouect\", \"haedickehouectect\", \"ect\", \"please\", \"would\", \"pm\", \"cc\", \n",
    "        \"may\", \"e\", \"forwarded\", \"attached\", \"attach\", \"thanks\", \"could\", \"mail\", \"mailing\", \n",
    "        \"bcc\", \"dear\", \"thru\", \"forwarded\", \"hi\", \"hello\", \"much\", \"really\", \"susan\", \"j\", \n",
    "        \"q\", \"p\", \"pls\", \"thank\", \"ps\", \"sorry\", \"also\", \"might\", \"must\", \"call\", \"fw\", \n",
    "        \"fwd\", \"date\", \"sincerely\", \"sent\", \"http\", \"list\", \"asap\", \"corp\"\n",
    "    }\n",
    "    \n",
    "    # Update stop_words with your custom stopwords\n",
    "    stop_words.update(custom_stopwords)\n",
    "    \n",
    "    # Add additional stopwords if provided via parameter\n",
    "    # if additional_stopwords:\n",
    "    #     stop_words.update([word.lower() for word in additional_stopwords])\n",
    "    \n",
    "    # Remove stopwords (NLTK + custom + additional)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "# Optional: Add more stopwords if needed\n",
    "# extra_stopwords = ['world', 'prepare']\n",
    "\n",
    "# Enable tqdm for pandas in Jupyter\n",
    "tqdm.pandas()\n",
    "\n",
    "# Apply preprocessing with progress bar\n",
    "df['Cleaned_Content'] = df['Content'].progress_apply(\n",
    "    lambda x: preprocess_text(x)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7295c7a-bc41-41a8-ad5b-832818a19bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "152a6194-2864-48d6-8561-55787aa4d842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12106d18075e4878a76b043b37ae37bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/480062 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to convert text to tokens (BoW)\n",
    "def text_to_tokens(text):\n",
    "\n",
    "    # Tokenize into words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Enable tqdm for pandas in Jupyter\n",
    "tqdm.pandas()\n",
    "\n",
    "# Apply tokenization with progress bar and add as new column\n",
    "df['BoW'] = df['Cleaned_Content'].progress_apply(text_to_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "807dae1a-906f-4a35-9b5e-04fe7e676cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.drop(columns = 'Content',errors ='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caf3d19a-4cfc-4835-8c49-955d4f3246f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 480062 entries, 0 to 480061\n",
      "Data columns (total 14 columns):\n",
      " #   Column                     Non-Null Count   Dtype \n",
      "---  ------                     --------------   ----- \n",
      " 0   Message-ID                 480062 non-null  object\n",
      " 1   Date                       480062 non-null  object\n",
      " 2   Time                       480062 non-null  int64 \n",
      " 3   From                       480062 non-null  object\n",
      " 4   To                         480062 non-null  object\n",
      " 5   Subject                    480062 non-null  object\n",
      " 6   X-cc                       480062 non-null  object\n",
      " 7   X-bcc                      480062 non-null  object\n",
      " 8   Job_Title                  480062 non-null  object\n",
      " 9   Total_Sentence_Word_Count  480062 non-null  int64 \n",
      " 10  From_Names                 480062 non-null  object\n",
      " 11  To_Names                   480062 non-null  object\n",
      " 12  Cleaned_Content            480062 non-null  object\n",
      " 13  BoW                        480062 non-null  object\n",
      "dtypes: int64(2), object(12)\n",
      "memory usage: 51.3+ MB\n"
     ]
    }
   ],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5ffa5f3-6539-42e1-9906-6e41394797c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8be7032433049c3a0ff77d663cd5d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/480062 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to combine Date and Time, removing weekday\n",
    "def combine_date_time(date, time):\n",
    "    # Remove weekday and comma (e.g., 'Fri, ' -> '')\n",
    "    date_cleaned = re.sub(r'^(Mon|Tue|Wed|Thu|Fri|Sat|Sun),\\s*', '', date.strip())\n",
    "    # Combine with year\n",
    "    return f\"{date_cleaned} {time}\"\n",
    "\n",
    "# Enable tqdm for pandas in Jupyter\n",
    "tqdm.pandas()\n",
    "\n",
    "# Combine 'Date' and 'Time' into a new column 'DateTime'\n",
    "new_df['DateTime'] = new_df.progress_apply(lambda row: combine_date_time(row['Date'], row['Time']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49ae6ae2-705c-4984-a2a0-6a55ac2eb3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.drop(columns = ['Date','Time','Message-ID'],errors ='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c92cbf3-c0c4-4e1c-ba5e-9d0bd9d13cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9215e050-44be-4d7c-89aa-e4b19414ce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df.Job_Title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf791cf8-e414-4d3c-a209-7c53f90a3049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of email addresses to filter out\n",
    "emails_to_filter = [\n",
    "    'all.worldwide@enron.com',\n",
    "    'enron_announcements@enron.com',\n",
    "    'issuealert@scientech.com',\n",
    "    'outlook.team@enron.com',\n",
    "    'Worldwide@ENRON',\n",
    "    'dl-ga-all_enron_worldwide2@enron',\n",
    "    'no.address@enron.com'\n",
    "]\n",
    "\n",
    "# Normalize emails_to_filter to lowercase for case-insensitive matching\n",
    "emails_to_filter = [email.lower() for email in emails_to_filter]\n",
    "\n",
    "# Create new DataFrame including specified emails\n",
    "new_df2 = new_df[~new_df['From'].str.lower().isin(emails_to_filter)].copy()\n",
    "new_df3 = new_df2[~new_df2['To'].str.lower().isin(emails_to_filter)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e0d06cf-1c46-48f9-a4e4-0f7a30a856e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df3.to_csv('finalv1_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "342dda4d-e693-4c1d-9191-79a67f2cd4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in new_df3: 471937\n",
      "Number of missing values (NaN/None) in 'From': 0\n",
      "Number of empty strings ('') in 'From': 0\n",
      "Total rows with empty or missing 'From': 0\n"
     ]
    }
   ],
   "source": [
    "# 1. Count the number of rows in new_df3\n",
    "row_count = len(new_df3)\n",
    "print(f\"Number of rows in new_df3: {row_count}\")\n",
    "\n",
    "# 2. Check for empty or missing values in 'From' column\n",
    "# Count missing values (NaN or None)\n",
    "missing_count = new_df3['From'].isna().sum()\n",
    "print(f\"Number of missing values (NaN/None) in 'From': {missing_count}\")\n",
    "\n",
    "# Count empty strings ('')\n",
    "empty_string_count = (new_df3['From'] == '').sum()\n",
    "print(f\"Number of empty strings ('') in 'From': {empty_string_count}\")\n",
    "\n",
    "# Total rows with empty or missing 'From'\n",
    "total_empty_or_missing = missing_count + empty_string_count\n",
    "print(f\"Total rows with empty or missing 'From': {total_empty_or_missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f3ea567-42a0-4a4f-a477-239b2b5e719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_50k = new_df3.iloc[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bef35125-f33d-4f67-b850-cdfc67e992c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50000 entries, 0 to 51969\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   From                       50000 non-null  object\n",
      " 1   To                         50000 non-null  object\n",
      " 2   Subject                    50000 non-null  object\n",
      " 3   X-cc                       50000 non-null  object\n",
      " 4   X-bcc                      50000 non-null  object\n",
      " 5   Job_Title                  50000 non-null  object\n",
      " 6   Total_Sentence_Word_Count  50000 non-null  int64 \n",
      " 7   From_Names                 50000 non-null  object\n",
      " 8   To_Names                   50000 non-null  object\n",
      " 9   Cleaned_Content            50000 non-null  object\n",
      " 10  BoW                        50000 non-null  object\n",
      " 11  DateTime                   50000 non-null  object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_first_50k.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae1d6a72-2b6e-4981-b05a-879fc5149828",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_50k.to_csv('filter_50krows.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91b2f9b8-41c4-4980-8674-48afb18b6912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Total_Sentence_Word_Count</th>\n",
       "      <th>From_Names</th>\n",
       "      <th>To_Names</th>\n",
       "      <th>Cleaned_Content</th>\n",
       "      <th>BoW</th>\n",
       "      <th>DateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>john.lavorato@enron.com</td>\n",
       "      <td>Re:</td>\n",
       "      <td>X-bcc:</td>\n",
       "      <td>X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>139</td>\n",
       "      <td>phillip allen</td>\n",
       "      <td>john lavorato</td>\n",
       "      <td>traveling business meeting takes fun trip especially prepare presentation suggest holding business plan meetings take trip without formal business meetings even try get honest opinions whether trip even desired necessary far business meetings think productive try stimulate discussions across different groups working often presenter speaks others quiet waiting turn meetings better held round table discussion format suggestion go austin play golf rent ski boat jet skis flying somewhere takes time</td>\n",
       "      <td>[traveling, business, meeting, takes, fun, trip, especially, prepare, presentation, suggest, holding, business, plan, meetings, take, trip, without, formal, business, meetings, even, try, get, honest, opinions, whether, trip, even, desired, necessary, far, business, meetings, think, productive, try, stimulate, discussions, across, different, groups, working, often, presenter, speaks, others, quiet, waiting, turn, meetings, better, held, round, table, discussion, format, suggestion, go, austin, play, golf, rent, ski, boat, jet, skis, flying, somewhere, takes, time]</td>\n",
       "      <td>4 May 2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>randall.gay@enron.com</td>\n",
       "      <td>Mime-Version: 1.0</td>\n",
       "      <td>X-bcc:</td>\n",
       "      <td>X-Folder: \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>33</td>\n",
       "      <td>phillip allen</td>\n",
       "      <td>randall gay</td>\n",
       "      <td>randy send schedule salary level everyone scheduling group plus thoughts changes need made patti example phillip</td>\n",
       "      <td>[randy, send, schedule, salary, level, everyone, scheduling, group, plus, thoughts, changes, need, made, patti, example, phillip]</td>\n",
       "      <td>23 Oct 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>david.l.johnson@enron.com, john.shafer@enron.com</td>\n",
       "      <td>Mime-Version: 1.0</td>\n",
       "      <td>X-bcc:</td>\n",
       "      <td>X-Folder: \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>22</td>\n",
       "      <td>phillip allen</td>\n",
       "      <td>david l johnson, john shafer</td>\n",
       "      <td>following distribution updates phillip allen pallenenroncom mike grigsby mikegrigsbyenroncom keith holst kholstenroncom monique sanchez frank ermis john lavorato help phillip allen</td>\n",
       "      <td>[following, distribution, updates, phillip, allen, pallenenroncom, mike, grigsby, mikegrigsbyenroncom, keith, holst, kholstenroncom, monique, sanchez, frank, ermis, john, lavorato, help, phillip, allen]</td>\n",
       "      <td>22 Aug 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>mark.scott@enron.com</td>\n",
       "      <td>Re: High Speed Internet Access</td>\n",
       "      <td>X-bcc:</td>\n",
       "      <td>X-Folder: \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>31</td>\n",
       "      <td>phillip allen</td>\n",
       "      <td>mark scott</td>\n",
       "      <td>1 login pallen pw ke9davis dont think required isp 2 static ip address ip 6421690105 sub 255255255248 gate 6421690110 dns 15116418 3 0413 rc 105891</td>\n",
       "      <td>[1, login, pallen, pw, ke9davis, dont, think, required, isp, 2, static, ip, address, ip, 6421690105, sub, 255255255248, gate, 6421690110, dns, 15116418, 3, 0413, rc, 105891]</td>\n",
       "      <td>17 Oct 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>zimam@enron.com</td>\n",
       "      <td>FW: fixed forward or other Collar floor gas price terms</td>\n",
       "      <td>X-bcc:</td>\n",
       "      <td>X-Folder: \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>300</td>\n",
       "      <td>phillip allen</td>\n",
       "      <td>zimam</td>\n",
       "      <td>phillip k allenhouect 10162000 0142 buckner buck buckbucknerhoneywellcom 10122000 011221 pallenenroncom pallenenroncom fixed forward collar floor gas price terms phillip discussed phone conversation parallon 75 microturbine power generation deal national accounts customer developing proposal sell power customer fixed collarfloor price need corresponding term gas price microturbine onsite generation product developed honeywell generate electricity customer site degen using natural gas need best fixed price forward gas price deal 1 3 5 7 10 years annualseasonal supply microturbines generate fixed kwh customer opportunity sell customer kwh using microturbine sell turbines kwh deal limited risk forward gas price make deal work therein comes sempra energy gas trading truly proposing installing 180 240 units across large number stores 60100 san diego store number varies installation hurdles face small percent 68 hours day microturbine run time gas requirement 180 microturbines 227 302 mmcf per year gas requirement 240 microturbines 302 403 mmcf per year gas likely consumed september peak electric period gas price required burnertip price behind ldc san diego gas electric need detail breakout commodity transport cost firm interruptible additional questions give let assure real deal buck buckner pe mba manager business development planning big box retail sales honeywell power systems inc 8725 pan american frwy albuquerque nm 87113 5057986424 5057986050x 5052204129 8885013145</td>\n",
       "      <td>[phillip, k, allenhouect, 10162000, 0142, buckner, buck, buckbucknerhoneywellcom, 10122000, 011221, pallenenroncom, pallenenroncom, fixed, forward, collar, floor, gas, price, terms, phillip, discussed, phone, conversation, parallon, 75, microturbine, power, generation, deal, national, accounts, customer, developing, proposal, sell, power, customer, fixed, collarfloor, price, need, corresponding, term, gas, price, microturbine, onsite, generation, product, developed, honeywell, generate, electricity, customer, site, degen, using, natural, gas, need, best, fixed, price, forward, gas, price, deal, 1, 3, 5, 7, 10, years, annualseasonal, supply, microturbines, generate, fixed, kwh, customer, opportunity, sell, customer, kwh, using, microturbine, sell, turbines, kwh, deal, limited, risk, forward, gas, price, make, deal, work, therein, comes, ...]</td>\n",
       "      <td>16 Oct 2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      From                                                To  \\\n",
       "0  phillip.allen@enron.com                           john.lavorato@enron.com   \n",
       "1  phillip.allen@enron.com                             randall.gay@enron.com   \n",
       "2  phillip.allen@enron.com  david.l.johnson@enron.com, john.shafer@enron.com   \n",
       "3  phillip.allen@enron.com                              mark.scott@enron.com   \n",
       "4  phillip.allen@enron.com                                   zimam@enron.com   \n",
       "\n",
       "                                                   Subject    X-cc  \\\n",
       "0                                                      Re:  X-bcc:   \n",
       "1                                        Mime-Version: 1.0  X-bcc:   \n",
       "2                                        Mime-Version: 1.0  X-bcc:   \n",
       "3                           Re: High Speed Internet Access  X-bcc:   \n",
       "4  FW: fixed forward or other Collar floor gas price terms  X-bcc:   \n",
       "\n",
       "                                                             X-bcc Job_Title  \\\n",
       "0  X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail   Unknown   \n",
       "1        X-Folder: \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail   Unknown   \n",
       "2        X-Folder: \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail   Unknown   \n",
       "3        X-Folder: \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail   Unknown   \n",
       "4        X-Folder: \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail   Unknown   \n",
       "\n",
       "   Total_Sentence_Word_Count     From_Names                      To_Names  \\\n",
       "0                        139  phillip allen                 john lavorato   \n",
       "1                         33  phillip allen                   randall gay   \n",
       "2                         22  phillip allen  david l johnson, john shafer   \n",
       "3                         31  phillip allen                    mark scott   \n",
       "4                        300  phillip allen                         zimam   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Cleaned_Content  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  traveling business meeting takes fun trip especially prepare presentation suggest holding business plan meetings take trip without formal business meetings even try get honest opinions whether trip even desired necessary far business meetings think productive try stimulate discussions across different groups working often presenter speaks others quiet waiting turn meetings better held round table discussion format suggestion go austin play golf rent ski boat jet skis flying somewhere takes time   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     randy send schedule salary level everyone scheduling group plus thoughts changes need made patti example phillip   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 following distribution updates phillip allen pallenenroncom mike grigsby mikegrigsbyenroncom keith holst kholstenroncom monique sanchez frank ermis john lavorato help phillip allen   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  1 login pallen pw ke9davis dont think required isp 2 static ip address ip 6421690105 sub 255255255248 gate 6421690110 dns 15116418 3 0413 rc 105891   \n",
       "4  phillip k allenhouect 10162000 0142 buckner buck buckbucknerhoneywellcom 10122000 011221 pallenenroncom pallenenroncom fixed forward collar floor gas price terms phillip discussed phone conversation parallon 75 microturbine power generation deal national accounts customer developing proposal sell power customer fixed collarfloor price need corresponding term gas price microturbine onsite generation product developed honeywell generate electricity customer site degen using natural gas need best fixed price forward gas price deal 1 3 5 7 10 years annualseasonal supply microturbines generate fixed kwh customer opportunity sell customer kwh using microturbine sell turbines kwh deal limited risk forward gas price make deal work therein comes sempra energy gas trading truly proposing installing 180 240 units across large number stores 60100 san diego store number varies installation hurdles face small percent 68 hours day microturbine run time gas requirement 180 microturbines 227 302 mmcf per year gas requirement 240 microturbines 302 403 mmcf per year gas likely consumed september peak electric period gas price required burnertip price behind ldc san diego gas electric need detail breakout commodity transport cost firm interruptible additional questions give let assure real deal buck buckner pe mba manager business development planning big box retail sales honeywell power systems inc 8725 pan american frwy albuquerque nm 87113 5057986424 5057986050x 5052204129 8885013145   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    BoW  \\\n",
       "0                                                                                                                                                                                                                                                                                            [traveling, business, meeting, takes, fun, trip, especially, prepare, presentation, suggest, holding, business, plan, meetings, take, trip, without, formal, business, meetings, even, try, get, honest, opinions, whether, trip, even, desired, necessary, far, business, meetings, think, productive, try, stimulate, discussions, across, different, groups, working, often, presenter, speaks, others, quiet, waiting, turn, meetings, better, held, round, table, discussion, format, suggestion, go, austin, play, golf, rent, ski, boat, jet, skis, flying, somewhere, takes, time]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [randy, send, schedule, salary, level, everyone, scheduling, group, plus, thoughts, changes, need, made, patti, example, phillip]   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [following, distribution, updates, phillip, allen, pallenenroncom, mike, grigsby, mikegrigsbyenroncom, keith, holst, kholstenroncom, monique, sanchez, frank, ermis, john, lavorato, help, phillip, allen]   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [1, login, pallen, pw, ke9davis, dont, think, required, isp, 2, static, ip, address, ip, 6421690105, sub, 255255255248, gate, 6421690110, dns, 15116418, 3, 0413, rc, 105891]   \n",
       "4  [phillip, k, allenhouect, 10162000, 0142, buckner, buck, buckbucknerhoneywellcom, 10122000, 011221, pallenenroncom, pallenenroncom, fixed, forward, collar, floor, gas, price, terms, phillip, discussed, phone, conversation, parallon, 75, microturbine, power, generation, deal, national, accounts, customer, developing, proposal, sell, power, customer, fixed, collarfloor, price, need, corresponding, term, gas, price, microturbine, onsite, generation, product, developed, honeywell, generate, electricity, customer, site, degen, using, natural, gas, need, best, fixed, price, forward, gas, price, deal, 1, 3, 5, 7, 10, years, annualseasonal, supply, microturbines, generate, fixed, kwh, customer, opportunity, sell, customer, kwh, using, microturbine, sell, turbines, kwh, deal, limited, risk, forward, gas, price, make, deal, work, therein, comes, ...]   \n",
       "\n",
       "      DateTime  \n",
       "0   4 May 2001  \n",
       "1  23 Oct 2000  \n",
       "2  22 Aug 2000  \n",
       "3  17 Oct 2000  \n",
       "4  16 Oct 2000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_first_50k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c3e1fd-12cf-4131-b332-dda1e44fc475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'lemmatizer'])\n",
    "# Batch POS tagging with spaCy\n",
    "df['POS_Tags'] = [\n",
    "    [(token.text, token.pos_) for token in doc]\n",
    "    for doc in nlp.pipe(tqdm(df['BoW'].str.join(' '), desc=\"POS Tagging\"), batch_size=1000)\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
